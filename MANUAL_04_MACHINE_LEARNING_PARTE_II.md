# Manual de Machine Learning - Sistema Hidr√°ulico Industrial - Parte II

## üìã Continua√ß√£o - An√°lise Espectral e Temporal

---

## üéµ Features Espectrais

### An√°lise de Dom√≠nio da Frequ√™ncia

As features espectrais capturam caracter√≠sticas no **dom√≠nio da frequ√™ncia**, essenciais para detectar padr√µes oscilat√≥rios e componentes harm√¥nicas indicativas de problemas operacionais.

#### üî¨ Implementa√ß√£o da An√°lise Espectral

```python
def _extract_spectral_features(self, features, feature_names, exp_pressure, rec_pressure):
    """
    Extrai features espectrais avan√ßadas usando FFT
    
    Para press√£o expedidor e recebedor:
    1. Energia em baixa frequ√™ncia (0 - 10% Nyquist)
    2. Energia em m√©dia frequ√™ncia (10% - 30% Nyquist)  
    3. Energia em alta frequ√™ncia (30% - 100% Nyquist)
    4. Frequ√™ncia dominante
    
    Total: 2 sinais √ó 4 features = 8 features espectrais
    """
    
    for signal, name in [(exp_pressure, 'exp_p'), (rec_pressure, 'rec_p')]:
        # FFT do sinal
        fft_signal = np.fft.fft(signal)
        freqs = np.fft.fftfreq(len(signal))
        magnitude = np.abs(fft_signal)
        
        # Define bandas de frequ√™ncia
        low_freq_mask = np.abs(freqs) < 0.1      # 0-10% da frequ√™ncia de Nyquist
        mid_freq_mask = (np.abs(freqs) >= 0.1) & (np.abs(freqs) < 0.3)  # 10-30%
        high_freq_mask = np.abs(freqs) >= 0.3    # 30-100%
        
        # Energia total para normaliza√ß√£o
        total_energy = np.sum(magnitude)
        
        # Energias por banda (normalizadas)
        low_energy = np.sum(magnitude[low_freq_mask]) / max(total_energy, 1e-10)
        mid_energy = np.sum(magnitude[mid_freq_mask]) / max(total_energy, 1e-10)
        high_energy = np.sum(magnitude[high_freq_mask]) / max(total_energy, 1e-10)
        
        # Frequ√™ncia dominante (apenas frequ√™ncias positivas)
        positive_freqs = freqs[:len(freqs)//2]
        positive_magnitude = magnitude[:len(magnitude)//2]
        dominant_freq_idx = np.argmax(positive_magnitude)
        dominant_freq = positive_freqs[dominant_freq_idx]
        
        features.extend([low_energy, mid_energy, high_energy, dominant_freq])
        feature_names.extend([
            f'{name}_low_energy', f'{name}_mid_energy', f'{name}_high_energy', f'{name}_dom_freq'
        ])
```

#### üìä Interpreta√ß√£o das Bandas Espectrais

##### **Energia em Baixa Frequ√™ncia (0-10% Nyquist)**

```python
def interpret_low_frequency_energy(self, low_energy_ratio):
    """
    Interpreta energia em baixa frequ√™ncia
    
    Caracter√≠sticas:
    - Tend√™ncias de longo prazo
    - Componente DC
    - Varia√ß√µes lentas de press√£o
    """
    
    if low_energy_ratio > 0.8:
        return {
            'interpretation': 'Domin√¢ncia de componentes lentas',
            'indication': 'Sistema est√°vel, poss√≠vel drift lento',
            'action': 'Monitorar tend√™ncias de longo prazo'
        }
    elif low_energy_ratio < 0.3:
        return {
            'interpretation': 'Baixa energia em componentes lentas',
            'indication': 'Poss√≠vel instabilidade ou ru√≠do dominante',
            'action': 'Investigar fontes de ru√≠do de alta frequ√™ncia'
        }
    else:
        return {
            'interpretation': 'Distribui√ß√£o espectral equilibrada',
            'indication': 'Sistema com comportamento normal',
            'action': 'Monitoramento rotineiro'
        }
```

##### **Energia em Alta Frequ√™ncia (30-100% Nyquist)**

```python
def interpret_high_frequency_energy(self, high_energy_ratio):
    """
    Interpreta energia em alta frequ√™ncia
    
    Caracter√≠sticas:
    - Ru√≠do de instrumenta√ß√£o
    - Turbul√™ncia local
    - Vibra√ß√µes mec√¢nicas
    - Poss√≠veis vazamentos (jato turbulento)
    """
    
    if high_energy_ratio > 0.3:
        return {
            'interpretation': 'Alta energia em componentes r√°pidas',
            'indication': 'Poss√≠vel turbul√™ncia, vazamento ou ru√≠do',
            'severity': 'Alto',
            'action': 'Investiga√ß√£o imediata recomendada'
        }
    elif high_energy_ratio > 0.15:
        return {
            'interpretation': 'Energia moderada em alta frequ√™ncia',
            'indication': 'Poss√≠vel in√≠cio de instabilidade',
            'severity': 'Moderado',
            'action': 'Monitoramento intensificado'
        }
    else:
        return {
            'interpretation': 'Baixa energia em alta frequ√™ncia',
            'indication': 'Sistema est√°vel, ru√≠do controlado',
            'severity': 'Baixo',
            'action': 'Monitoramento normal'
        }
```

#### üéº An√°lise de Harm√¥nicos

```python
def harmonic_analysis(self, signal, fundamental_freq=None):
    """
    An√°lise de conte√∫do harm√¥nico para detec√ß√£o de padr√µes peri√≥dicos
    
    Detecta:
    - Frequ√™ncia fundamental
    - Harm√¥nicos (2f, 3f, 4f, ...)
    - Distor√ß√£o harm√¥nica total (THD)
    - Componentes inter-harm√¥nicas
    """
    
    # FFT do sinal
    fft_signal = np.fft.fft(signal)
    freqs = np.fft.fftfreq(len(signal))
    magnitude = np.abs(fft_signal)
    
    # Encontra frequ√™ncia fundamental se n√£o fornecida
    if fundamental_freq is None:
        # Pico de maior magnitude (excluindo DC)
        positive_freqs = freqs[1:len(freqs)//2]  # Exclui DC e negativos
        positive_magnitude = magnitude[1:len(magnitude)//2]
        fundamental_idx = np.argmax(positive_magnitude)
        fundamental_freq = positive_freqs[fundamental_idx]
    
    # Localiza harm√¥nicos
    harmonics = {}
    total_power = np.sum(magnitude**2)
    fundamental_power = 0
    
    for n in range(1, 6):  # At√© 5¬∫ harm√¥nico
        harmonic_freq = n * fundamental_freq
        
        # Encontra bin mais pr√≥ximo da frequ√™ncia harm√¥nica
        harmonic_idx = np.argmin(np.abs(freqs - harmonic_freq))
        harmonic_magnitude = magnitude[harmonic_idx]
        harmonic_power = harmonic_magnitude**2
        
        if n == 1:
            fundamental_power = harmonic_power
        
        harmonics[f'harmonic_{n}'] = {
            'frequency': freqs[harmonic_idx],
            'magnitude': harmonic_magnitude,
            'power_ratio': harmonic_power / max(total_power, 1e-10)
        }
    
    # Distor√ß√£o Harm√¥nica Total (THD)
    harmonic_powers = sum([h['magnitude']**2 for n, h in harmonics.items() if n != 'harmonic_1'])
    thd = np.sqrt(harmonic_powers / max(fundamental_power, 1e-10)) * 100  # Percentual
    
    return {
        'fundamental_frequency': fundamental_freq,
        'harmonics': harmonics,
        'thd_percent': thd,
        'spectral_quality': 'clean' if thd < 5 else 'distorted' if thd < 15 else 'heavily_distorted'
    }
```

---

## ‚è±Ô∏è Features de Estabilidade Temporal

### An√°lise de Persist√™ncia e Flutua√ß√µes

As features temporais quantificam a **estabilidade** dos sinais ao longo do tempo, usando janelas m√≥veis para detectar mudan√ßas graduais.

#### üìà Implementa√ß√£o da An√°lise Temporal

```python
def _extract_temporal_features(self, features, feature_names, exp_pressure, rec_pressure, flow):
    """
    Extrai features de estabilidade temporal usando janelas m√≥veis
    
    Para press√£o expedidor, press√£o recebedor e fluxo:
    1. Estabilidade m√©dia em janela m√≥vel
    2. M√°ximo coeficiente de varia√ß√£o local
    
    Total: 3 sinais √ó 2 features = 6 features temporais
    """
    
    for signal, name in [(exp_pressure, 'exp_p'), (rec_pressure, 'rec_p'), (flow, 'flow')]:
        # Janela m√≥vel adaptativa
        window_size = min(10, len(signal)//4)
        
        if window_size > 1:
            stabilities = []
            cv_locals = []  # Coeficientes de varia√ß√£o locais
            
            # An√°lise em janelas deslizantes
            for i in range(len(signal) - window_size + 1):
                window_data = signal[i:i + window_size]
                
                # Estabilidade = 1 / (1 + coeficiente de varia√ß√£o)
                mean_window = np.mean(window_data)
                std_window = np.std(window_data)
                cv = std_window / max(abs(mean_window), 1e-6)  # Coef. varia√ß√£o
                
                stability = 1.0 / (1.0 + cv)
                stabilities.append(stability)
                cv_locals.append(cv)
            
            stability_mean = np.mean(stabilities)
            cv_max = np.max(cv_locals)
        else:
            # Dados insuficientes para janela m√≥vel
            stability_mean = 1.0  # Assumir est√°vel
            cv_max = 0.0
        
        features.extend([stability_mean, cv_max])
        feature_names.extend([f'{name}_stability', f'{name}_cv_max'])
```

#### üéØ M√©tricas de Estabilidade

##### **Coeficiente de Varia√ß√£o Local**

```
CV = œÉ_window / |Œº_window|
```

- **Interpreta√ß√£o**: Variabilidade relativa em cada janela
- **Aplica√ß√£o**: Detecta regi√µes de instabilidade localizada
- **Vazamentos**: CV elevado indica flutua√ß√µes caracter√≠sticas

##### **√çndice de Estabilidade**

```
Stability = 1 / (1 + CV)
```

- **Valores**: 0 (inst√°vel) a 1 (perfeitamente est√°vel)
- **Interpreta√ß√£o**: Resist√™ncia a flutua√ß√µes
- **Aplica√ß√£o**: Quantifica qualidade operacional

#### üîç An√°lise de Mudan√ßas de Regime

```python
def detect_regime_changes(self, signal, min_regime_length=20):
    """
    Detecta mudan√ßas de regime operacional usando CUSUM e an√°lise de vari√¢ncia
    
    Identifica:
    - Pontos de mudan√ßa na m√©dia
    - Pontos de mudan√ßa na vari√¢ncia  
    - Dura√ß√£o de cada regime
    - Caracteriza√ß√£o dos regimes
    """
    
    # CUSUM para detec√ß√£o de mudan√ßa na m√©dia
    mean_baseline = np.mean(signal)
    cusum_pos = np.zeros(len(signal))
    cusum_neg = np.zeros(len(signal))
    
    drift = 0.01 * np.std(signal)  # Drift m√≠nimo para detec√ß√£o
    threshold = 3 * np.std(signal)  # Threshold de detec√ß√£o
    
    change_points_mean = []
    
    for i in range(1, len(signal)):
        # CUSUM acumulativo
        cusum_pos[i] = max(0, cusum_pos[i-1] + signal[i] - mean_baseline - drift)
        cusum_neg[i] = max(0, cusum_neg[i-1] - signal[i] + mean_baseline - drift)
        
        # Detec√ß√£o de mudan√ßa
        if cusum_pos[i] > threshold or cusum_neg[i] > threshold:
            change_points_mean.append(i)
            # Reset CUSUM
            cusum_pos[i] = 0
            cusum_neg[i] = 0
    
    # An√°lise de mudan√ßa na vari√¢ncia usando F-test em janelas
    change_points_variance = []
    window_size = min(50, len(signal)//5)
    
    for i in range(window_size, len(signal) - window_size):
        # Janelas antes e depois do ponto candidato
        before_window = signal[i-window_size:i]
        after_window = signal[i:i+window_size]
        
        # F-test para igualdade de vari√¢ncias
        var_before = np.var(before_window)
        var_after = np.var(after_window)
        
        f_ratio = max(var_before, var_after) / max(min(var_before, var_after), 1e-10)
        
        # Threshold emp√≠rico para F-test
        if f_ratio > 2.5:  # Mudan√ßa significativa na vari√¢ncia
            change_points_variance.append(i)
    
    # Consolida pontos de mudan√ßa
    all_changes = sorted(set(change_points_mean + change_points_variance))
    
    # Remove pontos muito pr√≥ximos
    filtered_changes = []
    for change in all_changes:
        if not filtered_changes or change - filtered_changes[-1] > min_regime_length:
            filtered_changes.append(change)
    
    # Caracteriza cada regime
    regimes = []
    start_points = [0] + filtered_changes
    end_points = filtered_changes + [len(signal)]
    
    for i, (start, end) in enumerate(zip(start_points, end_points)):
        regime_data = signal[start:end]
        
        regimes.append({
            'regime_id': i + 1,
            'start_index': start,
            'end_index': end,
            'duration': end - start,
            'mean_level': np.mean(regime_data),
            'std_level': np.std(regime_data),
            'trend': np.polyfit(range(len(regime_data)), regime_data, 1)[0] if len(regime_data) > 1 else 0.0
        })
    
    return {
        'n_regimes': len(regimes),
        'change_points': filtered_changes,
        'regimes': regimes,
        'stability_score': 1.0 / max(1, len(filtered_changes))  # Mais mudan√ßas = menos est√°vel
    }
```

---

## üîó Rela√ß√µes Entre Vari√°veis

### Correla√ß√µes Cruzadas Multivari√°veis

As features relacionais capturam **intera√ß√µes entre diferentes vari√°veis**, essenciais para compreender o comportamento sist√™mico do processo hidr√°ulico.

#### üéØ Implementa√ß√£o das Correla√ß√µes Cruzadas

```python
def _extract_relational_features(self, features, feature_names, exp_pressure, rec_pressure, flow, density, temperature):
    """
    Extrai features baseadas em correla√ß√µes entre pares de vari√°veis
    
    Pares analisados:
    1. (Diferen√ßa de press√£o) vs (Fluxo)
    2. (Densidade) vs (Temperatura)  
    3. (Fluxo) vs (Temperatura)
    4. (Diferen√ßa de press√£o) vs (Densidade)
    
    Total: 4 pares √ó 2 features = 8 features relacionais
    """
    
    # Calcula diferen√ßa de press√£o (indicador de for√ßa motriz)
    pressure_diff = exp_pressure - rec_pressure
    
    # Define pares de vari√°veis para an√°lise
    variable_pairs = [
        (pressure_diff, flow, 'press_diff_flow'),      # Lei de Darcy-Weisbach
        (density, temperature, 'density_temp'),        # Rela√ß√£o termodin√¢mica
        (flow, temperature, 'flow_temp'),              # Efeito t√©rmico no fluxo
        (pressure_diff, density, 'press_diff_density') # Efeito barom√©trico
    ]
    
    correlations = []
    correlation_names = []
    
    for var1, var2, name in variable_pairs:
        if len(var1) > 1 and len(var2) > 1:
            # Correla√ß√£o de Pearson
            try:
                corr_matrix = np.corrcoef(var1, var2)
                correlation = corr_matrix[0, 1]
                
                # Trata NaN (vari√°veis constantes)
                if np.isnan(correlation):
                    correlation = 0.0
                
            except:
                correlation = 0.0
            
            # Correla√ß√£o cruzada com delay (correla√ß√£o m√°xima com lag)
            try:
                cross_corr = signal.correlate(var1 - np.mean(var1), var2 - np.mean(var2), mode='full')
                cross_corr_normalized = cross_corr / (len(var1) * np.std(var1) * np.std(var2))
                max_cross_corr = np.max(np.abs(cross_corr_normalized))
                
                if np.isnan(max_cross_corr):
                    max_cross_corr = 0.0
                    
            except:
                max_cross_corr = 0.0
        else:
            correlation = 0.0
            max_cross_corr = 0.0
        
        correlations.extend([correlation, max_cross_corr])
        correlation_names.extend([f'corr_{name}', f'xcorr_max_{name}'])
    
    features.extend(correlations)
    feature_names.extend(correlation_names)
```

#### üìä Interpreta√ß√£o F√≠sica das Correla√ß√µes

##### **Diferen√ßa de Press√£o vs Fluxo**

```python
def interpret_pressure_flow_correlation(self, correlation):
    """
    Interpreta correla√ß√£o entre diferen√ßa de press√£o e fluxo
    
    Baseado na Equa√ß√£o de Darcy-Weisbach:
    ŒîP = f √ó (L/D) √ó (œÅV¬≤/2)
    
    Onde ŒîP ‚àù Q¬≤ (fluxo ao quadrado)
    """
    
    if correlation > 0.8:
        return {
            'interpretation': 'Correla√ß√£o forte e positiva',
            'physical_meaning': 'Comportamento hidr√°ulico normal',
            'flow_regime': 'Turbulento bem estabelecido',
            'system_health': 'Bom'
        }
    elif correlation > 0.5:
        return {
            'interpretation': 'Correla√ß√£o moderada',
            'physical_meaning': 'Poss√≠vel transi√ß√£o de regime ou perdas adicionais',
            'flow_regime': 'Transi√ß√£o laminar-turbulento',
            'system_health': 'Aten√ß√£o'
        }
    elif correlation < 0.3:
        return {
            'interpretation': 'Correla√ß√£o fraca ou ausente',
            'physical_meaning': 'Poss√≠vel vazamento, bloqueio ou instrumenta√ß√£o defeituosa',
            'flow_regime': 'Indeterminado',
            'system_health': 'Cr√≠tico'
        }
```

##### **Densidade vs Temperatura**

```python
def interpret_density_temperature_correlation(self, correlation):
    """
    Interpreta correla√ß√£o entre densidade e temperatura
    
    Baseado na equa√ß√£o de estado:
    œÅ = œÅ‚ÇÄ √ó [1 - Œ≤(T - T‚ÇÄ)]
    
    Onde Œ≤ √© o coeficiente de expans√£o t√©rmica
    """
    
    expected_correlation = -0.7  # Correla√ß√£o negativa esperada
    
    if correlation < -0.6:
        return {
            'interpretation': 'Correla√ß√£o negativa forte (esperada)',
            'physical_meaning': 'Expans√£o t√©rmica normal do fluido',
            'fluid_behavior': 'Conforme esperado',
            'measurement_quality': 'Boa'
        }
    elif correlation > -0.3:
        return {
            'interpretation': 'Correla√ß√£o negativa fraca ou positiva',
            'physical_meaning': 'Poss√≠vel mistura de fluidos, mudan√ßa de composi√ß√£o ou erro de instrumenta√ß√£o',
            'fluid_behavior': 'An√¥malo',
            'measurement_quality': 'Question√°vel'
        }
```

#### üîç An√°lise de Causalidade Temporal

```python
def granger_causality_analysis(self, var1, var2, max_lag=10):
    """
    Teste de Causalidade de Granger entre duas vari√°veis
    
    Determina se var1 "causa" var2 no sentido estat√≠stico:
    - var1 ajuda a predizer var2 melhor que apenas o hist√≥rico de var2
    """
    
    from statsmodels.tsa.stattools import grangercausalitytests
    
    try:
        # Prepara dados para teste
        data = np.column_stack([var2, var1])  # [y, x] - ordem importante
        
        # Executa teste de Granger
        results = grangercausalitytests(data, max_lag, verbose=False)
        
        # Extrai p-valores para diferentes lags
        p_values = {}
        f_statistics = {}
        
        for lag in range(1, max_lag + 1):
            if lag in results:
                test_result = results[lag][0]['ssr_ftest']
                p_values[lag] = test_result[1]  # p-valor
                f_statistics[lag] = test_result[0]  # estat√≠stica F
        
        # Determina o melhor lag (menor p-valor)
        best_lag = min(p_values.keys(), key=lambda k: p_values[k])
        best_p_value = p_values[best_lag]
        
        # Interpreta√ß√£o
        significance_level = 0.05
        is_causal = best_p_value < significance_level
        
        return {
            'is_causal': is_causal,
            'best_lag': best_lag,
            'p_value': best_p_value,
            'f_statistic': f_statistics[best_lag],
            'all_lags': {
                'p_values': p_values,
                'f_statistics': f_statistics
            },
            'interpretation': 'var1 Granger-causa var2' if is_causal else 'Sem causalidade detectada'
        }
        
    except Exception as e:
        return {
            'error': f'Erro no teste de Granger: {str(e)}',
            'is_causal': False,
            'p_value': 1.0
        }
```

---

## üé™ Integra√ß√£o de Features

### Vetor de Features Completo

Ao final do processo de extra√ß√£o, o sistema produz um **vetor de 81 features** altamente especializadas:

#### üìã Resumo das Features por Categoria

| Categoria | Quantidade | Descri√ß√£o | Aplica√ß√£o Principal |
|-----------|------------|-----------|-------------------|
| **Estat√≠sticas** | 45 | Momentos, percentis, tend√™ncias | Caracteriza√ß√£o b√°sica |
| **Gradientes** | 9 | Derivadas temporais | Detec√ß√£o de transientes |
| **Correla√ß√£o Cruzada** | 5 | An√°lise s√¥nica integrada | Propaga√ß√£o de ondas |
| **Espectrais** | 8 | Conte√∫do de frequ√™ncias | Padr√µes oscilat√≥rios |
| **Relacionais** | 8 | Correla√ß√µes entre vari√°veis | Comportamento sist√™mico |
| **Temporais** | 6 | Estabilidade e persist√™ncia | Mudan√ßas de regime |
| **TOTAL** | **81** | **Features altamente especializadas** | **Detec√ß√£o completa** |

#### üßÆ Vetor de Features Normalizado

```python
def prepare_feature_vector_for_ml(self, features_raw):
    """
    Prepara vetor de features para algoritmos de ML
    
    Processos:
    1. Normaliza√ß√£o Z-score
    2. Tratamento de outliers
    3. Preenchimento de valores faltantes
    4. Valida√ß√£o de consist√™ncia
    """
    
    # Remove NaN e infinitos
    features_clean = np.array(features_raw)
    nan_mask = np.isnan(features_clean) | np.isinf(features_clean)
    features_clean[nan_mask] = 0.0  # Ou mediana/interpola√ß√£o
    
    # Detec√ß√£o de outliers extremos (> 5 sigma)
    outlier_mask = np.abs(features_clean) > 5 * np.std(features_clean)
    features_clean[outlier_mask] = np.clip(
        features_clean[outlier_mask],
        -5 * np.std(features_clean),
        5 * np.std(features_clean)
    )
    
    # Normaliza√ß√£o usando scaler treinado
    if hasattr(self.scaler, 'scale_'):  # Scaler j√° foi treinado
        features_normalized = self.scaler.transform(features_clean.reshape(1, -1))[0]
    else:
        # Primeira vez - fit e transform
        features_normalized = features_clean  # Retorna sem normalizar
    
    # Valida√ß√£o final
    assert len(features_normalized) == 81, f"Esperadas 81 features, obtidas {len(features_normalized)}"
    assert not np.any(np.isnan(features_normalized)), "Features cont√™m NaN ap√≥s normaliza√ß√£o"
    
    return features_normalized
```

---

**CONTINUA√á√ÉO NA PARTE III**

A Parte II cobriu detalhadamente:

- ‚úÖ **Features Espectrais** - An√°lise FFT, bandas de frequ√™ncia, harm√¥nicos
- ‚úÖ **Features Temporais** - Estabilidade, janelas m√≥veis, mudan√ßas de regime  
- ‚úÖ **Features Relacionais** - Correla√ß√µes cruzadas, causalidade de Granger
- ‚úÖ **Integra√ß√£o de Features** - Vetor final de 81 features

**Pr√≥xima parte** - MANUAL_04_MACHINE_LEARNING_PARTE_III.md:

- üîÑ **Algoritmos ML** - Isolation Forest, Random Forest, SVM, DBSCAN
- üß† **Treinamento Adaptativo** - Retreino autom√°tico, threshold din√¢mico
- üìä **An√°lise PCA** - Redu√ß√£o de dimensionalidade, componentes principais
- üéØ **Predi√ß√£o e Fus√£o** - Combina√ß√£o de modelos, confidence scoring

Continuar com a Parte III?
